{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5344e3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/njfernandez/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No config specified, defaulting to: emotion/split\n",
      "Found cached dataset emotion (/home/njfernandez/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd)\n",
      "100%|██████████| 3/3 [00:00<00:00, 727.00it/s]\n",
      "Loading cached processed dataset at /home/njfernandez/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd/cache-da33b75eb48814c5.arrow\n",
      "Loading cached processed dataset at /home/njfernandez/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd/cache-c9fa37d993431ea5.arrow\n",
      "Loading cached processed dataset at /home/njfernandez/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd/cache-9e625d0ab4c5791f.arrow\n",
      "Loading cached processed dataset at /home/njfernandez/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd/cache-073a5a64cb90fedf.arrow\n",
      "Loading cached processed dataset at /home/njfernandez/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd/cache-395955177184ef62.arrow\n",
      "Loading cached processed dataset at /home/njfernandez/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd/cache-fb1228275c28ad89.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Seeding for deterministic results i.e. showing same output \n",
    "RANDOM_SEED = 64\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "   torch.cuda.manual_seed(RANDOM_SEED)\n",
    "   torch.cuda.manual_seed_all(RANDOM_SEED) \n",
    "   torch.backends.cudnn.deterministic = True  \n",
    "   torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "function_mapping = {'OTHER': ['joy', 'love', 'surprise'],\n",
    "           'NOT_INTERESTED': [''], \n",
    "           'DISLIKE':[''], \n",
    "           'NOT_CORRECT': [''], \n",
    "           'PESSIMISTIC':['sadness'], \n",
    "           'WORRIED':['fear'], \n",
    "           'ANGRY': ['anger'], \n",
    "           'DISAPPOINTED': [''], \n",
    "           'BORED': [''], \n",
    "           'NOT_APPROVE':[''], \n",
    "           'NOT_IMPORTANT': [''], \n",
    "           'DISAGREE': [''], \n",
    "           'WARN': [''], \n",
    "           'COMPLAIN': [''], \n",
    "           'THREATEN': [''], \n",
    "           'UNWILLING': [''], \n",
    "           'DISTRUST' : [''],\n",
    "           'REFUSE': [''] }\n",
    "\n",
    "emotion = load_dataset('emotion')\n",
    "mapping = {\n",
    "    0:\"sadness\",\n",
    "    1:\"joy\",\n",
    "    2:\"love\",\n",
    "    3:\"anger\",\n",
    "    4:\"fear\",\n",
    "    5:\"surprise\"\n",
    "}\n",
    "emotion = emotion.map(lambda example: {'emotion': mapping[example['label']]}, \n",
    "                      remove_columns=['label'])\n",
    "def map_labels(batch):\n",
    "    batch['function'] = [[] for _ in range(len(batch['text']))]\n",
    "    for i, item in enumerate(batch[\"function\"]):\n",
    "        for key, value in function_mapping.items():\n",
    "            for emotion in value:\n",
    "                if emotion == batch[\"emotion\"][i]:\n",
    "                    batch[\"function\"][i] = key\n",
    "                    break\n",
    "    return batch\n",
    "emotion = emotion.map(map_labels, batched=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d564df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_model='MoritzLaurer/mDeBERTa-v3-base-mnli-xnli'\n",
    "candidate_labels= {#\"lack of interest\": \"NOT_INTERESTED\",\n",
    "                   #\"boredom\": \"BORED\",\n",
    "                   #\"disgust\": \"DISLIKE\", \n",
    "                   #\"incorrectness\": \"NOT_CORRECT\", \n",
    "                   \"sadness\": \"PESSIMISTIC\", \n",
    "                   \"fear\": \"WORRIED\", \n",
    "                   \"anger\": \"ANGRY\", \n",
    "                   #\"disappointment\": \"DISAPPOINTED\",\n",
    "                   #\"complaint\": \"COMPLAIN\",\n",
    "                   #\"disapproval\": \"NOT_APPROVE\",\n",
    "                   #\"unimportance\": \"NOT_IMPORTANT\", \n",
    "                   #\"disagreement\": \"DISAGREE\",\n",
    "                   #\"refusal\": \"REFUSE\",\n",
    "                  #\"warning\": \"WARN\", \n",
    "                  #\"threat\": \"THREATEN\",\n",
    "                  #\"unwillingness\": \"UNWILLING\",\n",
    "                  #\"distrust\": \"DISTRUST\",\n",
    "                  \"joy, surprise or other emotion\": \"OTHER\"}\n",
    "\n",
    "h_ts = ['This person feels {}.', 'This person conveys {}.','This person shows {}.','This person expresses {}.', \n",
    "        'This text is {}.', 'This text is about {}.', 'This text shows {}.', 'This text expresses {}.', 'This text conveys {}.',\n",
    "       'The communicative function of this text is {}.', 'The communicative intention of this text is {}.', 'The emotion of this text is {}.', \n",
    "        'The emotion expressed in this text is {}.'] # the templates used\n",
    "\n",
    "def zero_shot_pipeline(example):\n",
    "    output = classifier(example['text'], candidate_labels=list(candidate_labels.keys()), hypothesis_template=ht, multi_label=False)\n",
    "    labels_scores = {candidate_labels[key]: score for key, score in zip(output['labels'], output['scores'])}\n",
    "    label, score = sorted(labels_scores.items(), key=lambda kv: kv[1], reverse=True)[0]\n",
    "    return {\"predicted_label\": label, \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7f2169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/njfernandez/.local/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Parameter 'function'=<function zero_shot_pipeline at 0x7f28f777c4c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This person feels {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [00:00<01:38, 20.23ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:43<00:00, 19.39ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.43      0.50      0.46       275\n",
      "       OTHER       0.90      0.58      0.71       920\n",
      " PESSIMISTIC       0.56      0.43      0.48       581\n",
      "     WORRIED       0.27      0.77      0.40       224\n",
      "\n",
      "    accuracy                           0.55      2000\n",
      "   macro avg       0.54      0.57      0.51      2000\n",
      "weighted avg       0.67      0.55      0.57      2000\n",
      "\n",
      "This person conveys {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:43<00:00, 19.36ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.31      0.52      0.39       275\n",
      "       OTHER       0.89      0.52      0.65       920\n",
      " PESSIMISTIC       0.52      0.53      0.52       581\n",
      "     WORRIED       0.35      0.63      0.45       224\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.52      0.55      0.50      2000\n",
      "weighted avg       0.64      0.54      0.56      2000\n",
      "\n",
      "This person shows {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:38<00:00, 20.39ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.36      0.50      0.42       275\n",
      "       OTHER       0.88      0.53      0.66       920\n",
      " PESSIMISTIC       0.53      0.50      0.51       581\n",
      "     WORRIED       0.30      0.68      0.41       224\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.52      0.55      0.50      2000\n",
      "weighted avg       0.64      0.53      0.56      2000\n",
      "\n",
      "This person expresses {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:37<00:00, 20.58ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.49      0.43      0.46       275\n",
      "       OTHER       0.91      0.49      0.64       920\n",
      " PESSIMISTIC       0.48      0.47      0.47       581\n",
      "     WORRIED       0.26      0.79      0.39       224\n",
      "\n",
      "    accuracy                           0.51      2000\n",
      "   macro avg       0.53      0.55      0.49      2000\n",
      "weighted avg       0.65      0.51      0.54      2000\n",
      "\n",
      "This text is {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:37<00:00, 20.41ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.41      0.51      0.45       275\n",
      "       OTHER       0.85      0.66      0.74       920\n",
      " PESSIMISTIC       0.54      0.64      0.59       581\n",
      "     WORRIED       0.44      0.49      0.46       224\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.56      0.58      0.56      2000\n",
      "weighted avg       0.65      0.62      0.63      2000\n",
      "\n",
      "This text is about {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:37<00:00, 20.50ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.41      0.51      0.45       275\n",
      "       OTHER       0.85      0.65      0.74       920\n",
      " PESSIMISTIC       0.56      0.60      0.58       581\n",
      "     WORRIED       0.41      0.59      0.48       224\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.56      0.59      0.56      2000\n",
      "weighted avg       0.65      0.61      0.62      2000\n",
      "\n",
      "This text shows {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:38<00:00, 20.32ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.37      0.50      0.42       275\n",
      "       OTHER       0.87      0.60      0.71       920\n",
      " PESSIMISTIC       0.54      0.56      0.55       581\n",
      "     WORRIED       0.35      0.60      0.44       224\n",
      "\n",
      "    accuracy                           0.57      2000\n",
      "   macro avg       0.53      0.56      0.53      2000\n",
      "weighted avg       0.65      0.57      0.59      2000\n",
      "\n",
      "This text expresses {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:43<00:00, 19.41ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.46      0.43      0.44       275\n",
      "       OTHER       0.89      0.53      0.66       920\n",
      " PESSIMISTIC       0.47      0.53      0.50       581\n",
      "     WORRIED       0.30      0.72      0.43       224\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.53      0.55      0.51      2000\n",
      "weighted avg       0.64      0.54      0.56      2000\n",
      "\n",
      "This text conveys {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:38<00:00, 20.33ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.40      0.52      0.45       275\n",
      "       OTHER       0.87      0.56      0.68       920\n",
      " PESSIMISTIC       0.49      0.62      0.55       581\n",
      "     WORRIED       0.38      0.54      0.44       224\n",
      "\n",
      "    accuracy                           0.57      2000\n",
      "   macro avg       0.54      0.56      0.53      2000\n",
      "weighted avg       0.64      0.57      0.59      2000\n",
      "\n",
      "The communicative function of this text is {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:37<00:00, 20.50ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.50      0.43      0.46       275\n",
      "       OTHER       0.86      0.60      0.71       920\n",
      " PESSIMISTIC       0.52      0.63      0.57       581\n",
      "     WORRIED       0.33      0.63      0.43       224\n",
      "\n",
      "    accuracy                           0.59      2000\n",
      "   macro avg       0.55      0.57      0.54      2000\n",
      "weighted avg       0.65      0.59      0.60      2000\n",
      "\n",
      "The communicative intention of this text is {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:38<00:00, 20.37ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.51      0.41      0.45       275\n",
      "       OTHER       0.84      0.59      0.69       920\n",
      " PESSIMISTIC       0.49      0.69      0.58       581\n",
      "     WORRIED       0.36      0.52      0.43       224\n",
      "\n",
      "    accuracy                           0.59      2000\n",
      "   macro avg       0.55      0.55      0.54      2000\n",
      "weighted avg       0.64      0.59      0.60      2000\n",
      "\n",
      "The emotion of this text is {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:38<00:00, 20.28ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.52      0.41      0.46       275\n",
      "       OTHER       0.84      0.70      0.77       920\n",
      " PESSIMISTIC       0.58      0.62      0.60       581\n",
      "     WORRIED       0.38      0.66      0.48       224\n",
      "\n",
      "    accuracy                           0.64      2000\n",
      "   macro avg       0.58      0.60      0.58      2000\n",
      "weighted avg       0.67      0.64      0.64      2000\n",
      "\n",
      "The emotion expressed in this text is {}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?ex/s]/home/njfernandez/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 2000/2000 [01:37<00:00, 20.54ex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGRY       0.54      0.41      0.47       275\n",
      "       OTHER       0.83      0.72      0.77       920\n",
      " PESSIMISTIC       0.59      0.61      0.60       581\n",
      "     WORRIED       0.38      0.66      0.48       224\n",
      "\n",
      "    accuracy                           0.64      2000\n",
      "   macro avg       0.58      0.60      0.58      2000\n",
      "weighted avg       0.67      0.64      0.65      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "classifier = pipeline('zero-shot-classification', model=zero_shot_model, device=0)\n",
    "\n",
    "for ht in h_ts:\n",
    "    print(ht)\n",
    "    emotion['test'] = emotion['test'].map(zero_shot_pipeline)   \n",
    "    y_true = emotion['test'][\"function\"]\n",
    "    y_pred = emotion['test'][\"predicted_label\"]\n",
    "    clf_report = classification_report(\n",
    "            y_true, y_pred, zero_division=0)\n",
    "    print(clf_report)\n",
    "    clf_report = classification_report(\n",
    "            y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    df = pd.DataFrame(clf_report).transpose()\n",
    "    with open(f\"classification_report_emotion_ht={ht}_zero_shot.csv\", 'w') as csv_file:\n",
    "        df.to_csv(path_or_buf=csv_file)\n",
    "    ds_zero_shot = emotion['test'].to_pandas()\n",
    "    cols = [\"text\", \"emotion\", \"function\", \"predicted_label\", \"score\"]\n",
    "    df_test = ds_zero_shot[:][cols]\n",
    "    df_test.to_csv(f\"preds_emotion_ht={ht}_zero_shot.csv\",header =True, sep = '\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f4d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
